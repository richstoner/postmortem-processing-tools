
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Postmortem processing tools</title>

    <!-- Bootstrap core CSS -->
    <link href="bower_components/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">

        body {
            font-family: "Avenir Next";
        }

        h2 {
            font-weight: 700;
        }

        .smallimg {
            max-height: 600px;
            border: 0px solid #fff !important;
        }

        .addpadd {
            padding: 10px;
        }

        .padhead {
            padding-top: 40px;
        }

    </style>
  </head>

  <body>
    <div class="container ">

      <div class="page-header">
        <h2>Postmortem Processing Tools</h2>



      </div>

      <div class="row addpadd">
        <div class="col-sm-12">
          <h5>Version 1.0.0. Released on March 26, 2014</h5>
            <p>Source: <a href="https://github.com/richstoner/postmortem-processing-tools">http://github.com/richstoner/postmortem-processing-tools/</a></p>
            <p class="">Rich Stoner (<a href="http://richstoner.github.io">richstoner.github.io</a>)</p>


         </div>


      </div>

      <div class="row addpadd">

          <div class="col-sm-12">

             <p><a class="btn btn-success" href="//192.2.2.2:8888"><i class="glyphicon glyphicon-book"></i>
                 IPython notebooks</a> - a web-based tool to work
                 with python. <b>Processing examples are located here.</b> IPython runs on port 8888. </p>
             <p><a class="btn btn-default btn-sm" href="//192.2.2.2:9999">Supervisor Web Console</a> - An easy way to
                 restart IPython notebook. Supervisor runs on port 9999.</p>

              <!--Thrown together at last minute, don't blame me for the br's-->

          </div>



      </div>

      <div class="page-header">
        <h2>Postmortem Reconstruction workflow</h2>
      </div>

      <div class="row">

          <div class="col-sm-12">

            <div class="lead"></div>

            <img class="img-responsive" src="reconstruction-control.jpg"/>

            <p>High resolution postmortem image registration and layer reconstruction of human cortex from serially-sectioned of <em>in situ</em> hybridization images.</p>

          </div>

        </div>



      <div class="row padhead">

        <div class="col-sm-3">

            <h3 id="1tableofcontents">1. Table of Contents</h3>

            <ol>
            <li><strong>Table of Contents</strong></li>
            <li><strong>Problem description</strong>
            <ol><li>Registration</li>
            <li>Point extraction</li>
            <li>Reconstruction</li></ol></li>
            <li><strong>3D reconstruction pipeline</strong>
            <ol><li>Overview</li>
            <li>Using the vagrant box</li>
            <li>Using the IPython notebooks</li>
            <li>Navigating the source code</li></ol></li>
            <li><strong>Details about the processing environment</strong></li>
            <li><strong>Caveats</strong></li>
            </ol>

        </div>



        <div class="col-sm-9">
            <img class="img-responsive" src="Reconstruction-workflow.jpg"/>
        </div>

       </div>

      <div class="row padhead">

        <div class="col-sm-12">

            <h2 id="2problemdescription">2. Problem Description</h2>

            <h4 id="21registration">2.1. Registration</h4>

            <p>Given a series of labeled high resolution images from a piece of human cortex, find a way to register the images into a single stack. Challenges:</p>

            <pre><code>1) The images are very large (50k x 25k pixels, 1px = 1µm^2)

            2) Each image contains 2 sections of tissue

            3) Each label stains the tissue different

            4) Most of the ISH labels are very low contrast

            5) No fiducials (such as blockface images) were collected at time of processing</code></pre>

            <h4 id="22pointextraction">2.2. Point extraction</h4>

            <p>For each labeled image, extract the location of labeled cells. Challenges:</p>

            <pre><code>1) The images are very large (50k x 25k pixels, 1px = 1µm^2)

            2) Each image requires background removal</code></pre>

            <h4 id="23reconstruction">2.3. Reconstruction</h4>

            <p>For all pointsets for a single label, generate a volume representation of approximate expression. Challenges:</p>

            <pre><code>1) Each point set needs to be transformed with the appropriate transform generated from the stack registration

            2) Each 2D density representation has to be generated by convolving the transformed point cloud with a 2D gaussian

            3) Generating a 3D volume from 2D planes requires interpolating missing planes</code></pre>

            <p>Studies involving postmortem tissue are severely limited by the quantity and quality of the tissue available. In many scenarios, the initial experimental design fails to capture the feature of interest. </p>

        </div>
        </div>


        <div class="row padhead">

        <div class="col-sm-12">

            <h2 id="3pipelineprocessingenvironment">3. Pipeline processing environment</h2>

            <h3 id="31overview">3.1. Overview</h3>

            <p>The processing pipeline consists of three primary modules: stack registration, point extraction, and reconstruction. To run the processing steps necessary, we have created a virutal machine with the necessary configuration. </p>

            <p>We are providing a vagrant box with this release <a href="http://vagrantup.com">http://vagrantup.com</a>. The vagrant box provides a simple way to get started and check out some of the key functions in the pipeline. However, given the computational requirements for some of the tasks, it may be better to deploy a similar configuration on a large cluster or cloud instance. The original processing pipeline was run on local resources and eventually Amazon's EC2 compute cloud. </p>

            <h3 id="32usingthevagrantbox">3.2. Using the vagrant box</h3>

            <ol>
            <li><p>Install Vagrant <a href="http://www.vagrantup.com/downloads.html">http://www.vagrantup.com/downloads.html</a></p></li>
            <li><p>Clone this repository to a folder on your local machine</p>

            <p><code>git clone https://github.com/richstoner/postmortem-processing-tools.git</code></p></li>
            <li><p>cd into the directory</p>

            <p><code>cd postmortem-processing-tools</code></p></li>
            <li><p>Launch the instance</p>

            <p><code>vagrant up</code></p></li>
            <li><p>Wait for the instance to boot, the go to <a href="http://192.2.2.2">http://192.2.2.2</a> in a web browser for more information. </p></li>
            </ol>

            <h3 id="33usingtheipythonnotebooks">3.3. Using the IPython notebooks</h3>

            <p>Severa examples have been made availble as IPython (<a href="http://ipython.org">http://ipython.org</a>) notebooks. Once the instance has booted, you can get to these notebooks by going to <a href="http://192.2.2.2:8888">http://192.2.2.2:8888</a> in a web browser (chrome preferred). Be advised, the IPython notebooks have no restrictions in place regarding user access. Take proper precaution before making these ports available as public-facing web sites. </p>

            <h3 id="34navigatingthesourcecode">3.4. Navigating the source code</h3>

            <p>The source code consists of three major components, all located in the /src directory:</p>

            <p><strong>python</strong> - The majority of the code is contained within the python directory. Two main modules: aibs &amp; pmip, provide most of the functionality for the processing pipeline. The IPython notebooks demonstrate how to use some of this functionality. </p>

            <p><strong>fijimacros</strong> - These are ImageJ / FIJI macros that get run via command-line from a python wrapper (defined in pmip)</p>

            <p><strong>itkcpp</strong> - Several c++ files used for efficient image registration via <a href="itk.org">ITK</a>. Compiled binaries from this source code is located in /bin.</p>

            <p>IPython notebooks are located in the /notebooks, and this documentation is located in /documentation.</p>

                    </div>
        </div>


        <div class="row padhead">

        <div class="col-sm-12">


            <h2 id="4detailsabouttheprocessingenvironment">4. Details about the processing environment</h2>

            <p>Base: hashicorp/precise64 (ubuntu 12.04.3)</p>

            <p>Here is a short list of what you'd need to build your own version of this environment:</p>

            <ul>
            <li>ITK 3.x</li>
            <li>FIJI (ImageJ)</li>
            <li>Imagemagick</li>
            <li>Avconv</li>
            <li>Python 2.7</li>
            <li>Core scientific python components in anaconda distribution.</li>
            </ul>

            <p><em>Note: this pipeline was developed over the span of 3 years - most of the toolchain could be reduced to ITK + python
            modules.</em></p>

            <h4 id="beforeinstallinganything">Before installing anything</h4>

            <p>While logged in to the instance:</p>

            <p><code>sudo apt-get update; sudo apt-get upgrade</code></p>

            <h4 id="pythondependencies">Python dependencies</h4>

            <p>Install Conda (from contiuum analytics)</p>

            <p><code>wget http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh</code></p>

            <p><code>chmod +x ./Miniconda-latest-Linux-x86_64.sh</code></p>

            <p><code>./Miniconda-latest-Linux-x86_64.sh</code></p>

            <p>Install additional dependencies</p>

            <p><code>conda install anaconda</code></p>

            <h4 id="fiji">FIJI</h4>

            <p>Getting FIJI</p>

            <p><code>wget http://sourceforge.net/projects/fiji-bi/files/fiji/Madison/fiji-linux64-20110307.tar.bz2/download</code></p>

            <p><code>mv download fiji.tar.bz2</code></p>

            <p><code>tar xvjf fiji.tar.bz2</code></p>

            <h4 id="itkv32">ITK (v3.2)</h4>

            <p>Getting ITK v3.2 (hard version requirement)</p>

            <p><code>wget http://sourceforge.net/projects/itk/files/itk/3.20/InsightToolkit-3.20.1.tar.gz/download</code></p>

            <p><code>mv download itk32.tar.gz</code></p>

            <p><code>tar xvzf itk32.tar.gz</code></p>

            <p>Building ITK requires several steps and is not documented here. For more information, visit <a href="http://itk.org/ITK/resources/software.html">http://itk.org/ITK/resources/software.html</a></p>

            <h4 id="imagemagickavconv">Imagemagick &amp; avconv</h4>

            <p>To provide some additional commandline capabilities and video generation, we use avconv and imagemagick's convert &amp; composite tools.</p>

            <p><code>sudo apt-get install libav-tools</code></p>

            <p><code>sudo apt-get install imagemagick</code></p>

            <h4 id="processmanagement">Process management</h4>

            <p>Install supervisor (to manage ipython)</p>

            <p><code>sudo apt-get install supervisor</code></p>

            <p>Updated supervisor config to a) enable http and b) start ipython notebook (<em>Details not shown</em>)</p>

                    </div>
        </div>


        <div class="row padhead">

        <div class="col-sm-12">


            <h2 id="5caveats">5. Caveats</h2>

            <p><strong>Not all steps presently codified</strong> - Unfortunately, several steps have not been included
                in this release as they are primarily manual steps, specifically the final interpolation from generated volume stack to scale-correct volume stacks - and rendering. We leave this as an exercise to the user to figure out. </p>

            <ul>
            <li>For final interpolation, use ImageJ or FIJI</li>
            <li>For rendering, we suggest using either a) <a href="http://www.osirix-viewer.com/">Osirix</a> for volume rendering or b) <a href="http://www.cgl.ucsf.edu/chimera/">UCSF Chimera</a> for volume + surface rendering. </li>
            </ul>

            <p><strong>Some processing steps require a specific machine configuration</strong> - Several of the processing steps may not run (correctly, or at all) on the vagrant virtual machine. Consider this instance a preview of the pipeline rather than a fire-and-forget solution. </p>

            <p><em>*Examples: *</em></p>

            <p>Running ImageJ / Fiji particle analysis requires a workstation with X11 running (or hours of experimentation with Xvfb). It also requires ~10G available RAM.</p>

            <p>Extracting points via scikit image requires a machine with 10G available RAM. This could be avoided by optimizing around the RGB->HSV conversion of the large in-memory images. </p>

          </div>


      </div>


    </div> <!-- /container -->


    <br><br><br><br><br><br><br><br>


  </body>
</html>
